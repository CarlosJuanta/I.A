#CODIGO FUNCIONANDO ARDUINO Y WEBCAM:
import cv2
import numpy as np
import tensorflow as tf
from PIL import Image
import serial ,time

arduino = serial.Serial('COM4',9600)
time.sleep(1)

# # guia de nombres
# title = ['Bateria', 'Biologico', 'Vidrio Cafe', 'Carton', 'Ropa', 'Botella verde', 'Metal/lata', 'Papel', 'Plastico', 'Zapatos', 'Basura varia', 'Vidrio Blanco']

# Clases del modelo
classes = ['Reciclables', 'biodegradables', 'Reciclables', 'Reciclables', 'Reutilizables', 'Reciclables', 'Reciclables', 'Reciclables', 'Reciclables', 'Reutilizables', 'noreciclable', 'Reciclables']

# Cargar el modelo TFLite
model_path = 'C:/PROGRAMACION/tareaIa/modelobasura.tflite'
interpreter = tf.lite.Interpreter(model_path=model_path)
interpreter.allocate_tensors()

# Obtener los detalles del modelo
input_details = interpreter.get_input_details()
output_details = interpreter.get_output_details()
input_shape = input_details[0]['shape']
num_classes = output_details[0]['shape'][1]

# Función para preprocesar la imagen
def preprocess_image(image):
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    image = Image.fromarray(image)
    image = image.resize((input_shape[1], input_shape[2]))
    image = np.expand_dims(image, axis=0)
    image = image.astype(np.float32)
    image /= 255.0  # Normalizar los valores de píxel en el rango [0, 1]
    return image

# Función para realizar la predicción en una imagen
def predict_image(image):
    image = preprocess_image(image)

    # Configurar los datos de entrada
    interpreter.set_tensor(input_details[0]['index'], image)

    # Realizar la predicción
    interpreter.invoke()

    # Obtener los resultados
    output = interpreter.get_tensor(output_details[0]['index'])
    output = np.squeeze(output)

    # Obtener la clase con la mayor probabilidad
    predicted_class = np.argmax(output)
    predicted_label = classes[predicted_class]

    return predicted_label

# Inicializar la cámara web
cap = cv2.VideoCapture(0)

# Variables para controlar el tiempo de reconocimiento
start_time = time.time()
recognize_interval = 1  # Intervalo de reconocimiento en segundos

while True:
    # Capturar el cuadro de la cámara
    ret, frame = cap.read()

    # Verificar si es el momento de realizar el reconocimiento
    elapsed_time = time.time() - start_time
    if elapsed_time >= recognize_interval:
        # Realizar la predicción en la imagen
        predicted_label = predict_image(frame)
        
        # Enviar el resultado al Arduino (reemplaza esta línea con tu código real para enviar al Arduino)
        print("Enviando a Arduino:", predicted_label)
        arduino.write(predicted_label.encode())

        
        # Reiniciar el tiempo de reconocimiento
        start_time = time.time()

    # Mostrar la imagen en pantalla
    cv2.putText(frame, predicted_label, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
    cv2.imshow('Webcam', frame)

    # Salir al presionar la tecla 'q'
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# Liberar los recursos
arduino.close()
cap.release()
cv2.destroyAllWindows()